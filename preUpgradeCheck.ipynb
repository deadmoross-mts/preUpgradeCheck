{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:70% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# To change the column width of cells\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:70% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Libraries and functions\n",
    "# import libraries\n",
    "import subprocess\n",
    "import re\n",
    "from os import listdir\n",
    "import csv\n",
    "import datetime\n",
    "import time\n",
    "import json\n",
    "\n",
    "# function to parse lscpu command output\n",
    "def lscpuParser(response):\n",
    "    response = re.sub(' +',' ',response)\n",
    "    responseList = response.split('\\n')\n",
    "    responseData = {}\n",
    "    for each in responseList:\n",
    "        if each != '':\n",
    "            tempKey,tempVal = each.split(':')\n",
    "            tempKey = tempKey.strip()\n",
    "            tempVal = tempVal.strip()\n",
    "            responseData[tempKey] = tempVal\n",
    "        \n",
    "    return(responseData)\n",
    "\n",
    "# parse version data\n",
    "def versionParser(config):\n",
    "    config = config.replace('\"','')\n",
    "    config = config.replace(\"'\",'')\n",
    "    temp = config.split('=')\n",
    "    temp0 = temp[0].rstrip()\n",
    "    temp1 = temp[1].rstrip()\n",
    "    return([temp0,temp1])\n",
    "\n",
    "# the following function processes the response from df -BG command run on\n",
    "# exactly one path\n",
    "def processDfOutput(response):\n",
    "    # process response\n",
    "    response = response.replace('Mounted on','Mounted_on').replace('\\n',' ')\n",
    "    # remove extra spaces\n",
    "    temp = re.sub(' +',' ',response).split(' ')\n",
    "    # split the lists\n",
    "    labs = temp[0:6]\n",
    "    vals = temp[6:]\n",
    "\n",
    "    # create a dictionary\n",
    "    dfOutput = dict(zip(labs,vals))\n",
    "    \n",
    "    return(dfOutput)\n",
    "\n",
    "# create a function to execute bash commands\n",
    "def bashCMD(command):\n",
    "    # open a process\n",
    "    process = subprocess.Popen('/bin/bash', stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    # execute command and capture result\n",
    "    response, err = process.communicate(command)\n",
    "    # return response\n",
    "    return(response)\n",
    "\n",
    "# a function defined to run alation shell \"alation_conf\" command\n",
    "def alationConfQuery(configVal):\n",
    "    # define command\n",
    "    cmd = '''sudo chroot \"/opt/alation/alation\" /bin/su - alationadmin -c \"alation_conf {}\"'''.format(configVal)\n",
    "    response = bashCMD(cmd)\n",
    "    # parse out the response\n",
    "    key,val = response.replace('\\n','').split('=')\n",
    "    key,val = key.strip(),val.strip()\n",
    "    # return response\n",
    "    return(key,val)\n",
    "    \n",
    "def colPrint(inStr,color):\n",
    "    # create output templates\n",
    "    if color == 'G':\n",
    "        # all clear = green\n",
    "        colPrintOut = '\\x1b[6;30;42m' + '{}'.format(inStr) + '\\x1b[0m'\n",
    "    elif color == 'R':\n",
    "        # warning = red\n",
    "        colPrintOut = '\\x1b[6;30;41m' + '{}'.format(inStr) + '\\x1b[0m'\n",
    "    elif color == 'O':\n",
    "        # caution = orange\n",
    "        colPrintOut = '\\x1b[6;30;43m' + '{}'.format(inStr) + '\\x1b[0m'\n",
    "        \n",
    "    return(colPrintOut)\n",
    "\n",
    "schemaCheckCode = \"\"\"# import libraries\n",
    "import bootstrap_rosemeta\n",
    "from object_synchronization.service.equivalence import EquivalenceSetMaterializer, SchemaEquivalenceMaterializer\n",
    "from rosemeta.models import SchemaEquivalence, Table\n",
    "from rosemeta.models import CustomFieldValue\n",
    "from logical_metadata.models.models_values import PickerFieldValueDiff\n",
    "from rosemeta.models.enums import CustomFieldType\n",
    "from django.db import connection\n",
    "\n",
    "# safe limit\n",
    "GROUP_SAFE_LIMIT = 100000\n",
    "\n",
    "def check_schema_equivalence(checkSummary):\n",
    "    schema_groups = SchemaEquivalence.objects.all().values_list('group_id', flat=True).distinct()\n",
    "    for schema_eq_group_id in schema_groups:\n",
    "        checkSummary.append(\"Processing schema equivalence group {}\".format(schema_eq_group_id))\n",
    "        schema_ids = SchemaEquivalence.objects.filter(group_id=schema_eq_group_id).values_list('schema_id', flat=True)\n",
    "        table_groups = EquivalenceSetMaterializer._fetch_groups(Table._meta.db_table, 'schema_obj_id', schema_ids)\n",
    "        attr_groups = SchemaEquivalenceMaterializer._fetch_attr_groups(schema_ids)\n",
    "        checkSummary.append(\"Table equivalences groups: {}\".format(len(table_groups)))\n",
    "        checkSummary.append(\"Column equivalences groups: {}\".format(len(attr_groups)))\n",
    "        if len(table_groups) < GROUP_SAFE_LIMIT and len(attr_groups) < GROUP_SAFE_LIMIT:\n",
    "            checkSummary.append(\"Schema equivalence group {} is ok\".format(schema_eq_group_id))\n",
    "        else:\n",
    "            checkSummary.append(\"CAN NOT UPGRADE BECAUSE OF SCHEMA EQUIVALENCE({}) HAS TOO MANY CHILDREN GROUPS\".format(schema_eq_group_id))\n",
    "            return(False,checkSummary)\n",
    " \n",
    "    return (True,checkSummary)\n",
    "\n",
    "def check_picker_unicode(checkSummary):\n",
    "    cfv_qs = CustomFieldValue.objects.filter(\n",
    "        otype__in=['schema', 'data', 'table', 'attribute'],\n",
    "        field__field_type=CustomFieldType.PICKER).select_related('field')\n",
    " \n",
    "    try:\n",
    "        for cfv in cfv_qs:\n",
    "            PickerFieldValueDiff(new_value=cfv.value_text, op='migrate')\n",
    "    except Exception as e:\n",
    "        checkSummary.append(e.message)\n",
    "        checkSummary.append(\"CAN NOT UPGRADE DUE TO UNICODE VALUES PRESENT IN CUSTOM FIELD VALUE ({})\".format(cfv.id))\n",
    "        return(False,checkSummary)\n",
    "    return(True,checkSummary)\n",
    " \n",
    " \n",
    "def check_custom_fields_duplicate(checkSummary):\n",
    "    sql = \"SELECT oid, field_type, field_id, COUNT(*), array_agg(cfv.id \" \\\\\n",
    "          \"ORDER BY cfv\" \\\\\n",
    "          \".id) cfv_ids FROM rosemeta_customfieldvalue cfv JOIN \" \\\\\n",
    "          \"rosemeta_customfield cf ON cf.id = cfv.field_id WHERE otype in \" \\\\\n",
    "          \"('table', 'schema', 'data', 'attribute') \" \\\\\n",
    "          \"AND field_type IN (1, 2, 4, 7) GROUP BY oid, \" \\\\\n",
    "          \"field_type, \" \\\\\n",
    "          \"field_id HAVING COUNT(*) > 1 ORDER BY 4 DESC;\"\n",
    " \n",
    "    cursor = connection.cursor()\n",
    "    cursor.execute(sql)\n",
    "    res = cursor.fetchall()\n",
    " \n",
    "    if res:\n",
    "#        print \"CAN NOT UPGRADE - DUPLICATE CUSTOM FIELD VALUE RECORDS FOUND\"\n",
    "#        print res\n",
    "        return(False,checkSummary)\n",
    "    return(True,checkSummary)\n",
    " \n",
    " \n",
    "def run_all_checks(checkSummary):\n",
    "    r1,checkSummary = check_custom_fields_duplicate(checkSummary)\n",
    "    r2,checkSummary = check_picker_unicode(checkSummary)\n",
    "    r3,checkSummary = check_schema_equivalence(checkSummary)\n",
    "    if r1 and r2 and r3:\n",
    "        # ok to upgrade\n",
    "        print(\"flag:0,check1:{},check2:{},check3:{}\".format(str(r1),str(r2),str(r3)))\n",
    "    else:\n",
    "        print(\"flag:1,check1:{},check2:{},check3:{}\".format(str(r1),str(r2),str(r3)))\n",
    "        \n",
    "    summ = '|'.join(checkSummary)    \n",
    "    print(\"Schema Check Summary: {}\".format(summ))\n",
    "\n",
    "checkSummary = []      \n",
    "run_all_checks(checkSummary)\"\"\"\n",
    "\n",
    "# write schema check code to the correct location\n",
    "try:\n",
    "    with open('/opt/alation/alation/opt/alation/django/rosemeta/one_off_scripts/schemaEquivalance.py','w') as f:\n",
    "        f.writelines(schemaCheckCode)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# ## Version information check\n",
    "def versionCheck(summary):\n",
    "    # run the version check\n",
    "    # run bash command and get the response\n",
    "    cmd = \"\"\"sudo chroot \"/opt/alation/alation\" /bin/su - alation\n",
    "    cat /opt/alation/django/main/alation_version.py\"\"\"\n",
    "    response = bashCMD(cmd)\n",
    "    versionData = response.strip('\\n').split('\\n')\n",
    "\n",
    "    # find Alation major version number\n",
    "    for each in versionData:\n",
    "        if \"ALATION_MAJOR_VERSION\" in each:\n",
    "            majorVersion = int(each.split(' = ')[1])\n",
    "        elif \"ALATION_MINOR_VERSION\" in each:\n",
    "            minorVersion = int(each.split(' = ')[1])\n",
    "        elif \"ALATION_PATCH_VERSION\" in each:\n",
    "            patchVersion = int(each.split(' = ')[1])\n",
    "        elif \"ALATION_BUILD_VERSION\" in each:\n",
    "            buildVersion = int(each.split(' = ')[1])\n",
    "\n",
    "    version = str(majorVersion) + '.' + str(minorVersion) + '.' + str(patchVersion) + '.' + str(buildVersion)\n",
    "    \n",
    "    # check major version requirement\n",
    "    if majorVersion >= CRITICALVERSION:\n",
    "        print('Version > {} (current version = {}): '.format(CRITICALVERSION,version) + colPrint('OK!','G'))\n",
    "        summary.append('Version ({}) check passed: OK'.format(version))\n",
    "        versionFlag = True\n",
    "    else:\n",
    "        print('Version > {} (current version = {}): '.format(CRITICALVERSION,version) + colPrint('FAIL!','R'))\n",
    "        versionFlag = False\n",
    "        summary.append('Version ({}) check failed: FAIL'.format(version))\n",
    "\n",
    "    # check additional version information\n",
    "    if majorVersion <= 4:\n",
    "        if minorVersion <= 10:\n",
    "            flag410 = True\n",
    "            print('{} Be sure to follow 4.10.x or below version specific steps here: https://alationhelp.zendesk.com/hc/en-us/articles/360011041633-Release-Specific-Update-Pre-Checks'.format(colPrint('WARNING!','O')))\n",
    "            summary.append('Version ({}) is less than 4.10.x: WARNING'.format(version))\n",
    "        \n",
    "    else:\n",
    "        summary.append('Version ({}) is greater than 4.10.x: OK'.format(version))\n",
    "        flag410 = False\n",
    "        \n",
    "    return(versionData,majorVersion,minorVersion,patchVersion,buildVersion,version,versionFlag,flag410,summary)\n",
    "\n",
    "# ## Replication mode check\n",
    "def replicationCheck(summary):\n",
    "    # check replication\n",
    "    # define commands\n",
    "    cmd = \"curl -L --insecure http://localhost/monitor/replication/\"\n",
    "    # get response\n",
    "    response = bashCMD(cmd)\n",
    "    # process response\n",
    "    replicationMode = response.split('{')[1].split('}')[0].split(': ')[1].replace('\"','')\n",
    "\n",
    "    # check replication criteria\n",
    "    if replicationMode == 'standalone':\n",
    "        print('Replication mode standalone: ' + colPrint('OK!','G'))\n",
    "        summary.append('Replication mode is standalone: OK')\n",
    "        replicationFlag = True\n",
    "    else:\n",
    "        print(colPrint('REPLICATION MODE NOT STANDALONE!','R'))\n",
    "        replicationFlag = False\n",
    "        summary.append('Replication mode is not standalone: WARNING')\n",
    "    \n",
    "    return(summary,replicationMode,replicationFlag)\n",
    "    \n",
    "# ## Minimum space requirement check\n",
    "def minSpaceCheck(summary):\n",
    "    # check if a minimum of MINDISKSPACE GB space is free at /opt/alation/ by calling: df -h /opt/alation\n",
    "    # define command\n",
    "    cmd = \"\"\"sudo chroot \"/opt/alation/alation\" /bin/su - alation\n",
    "    df -BG /\"\"\"\n",
    "    # run bash command and get response\n",
    "    response = bashCMD(cmd)\n",
    "    # get df readout\n",
    "    installDfOutput = processDfOutput(response)\n",
    "    # get remaining disk space\n",
    "    availSize = float(re.sub(\"\\D\", \"\", installDfOutput['Available']))\n",
    "    # check if there is at least MINDISKSPACE GB space available\n",
    "    if availSize > MINDISKSPACE:\n",
    "        print('Minimum {}GB disk space (available = {}GB): '.format(MINDISKSPACE,availSize) + colPrint('OK!','G'))\n",
    "        summary.append('Minimum space requirement met: OK')\n",
    "        diskFlag = True\n",
    "    else:\n",
    "        print('Minimum 10GB disk space (available = {}GB): '.format(availSize) + colPrint('FAIL!','R'))\n",
    "        diskFlag = False\n",
    "        summary.append('Minimum space requirement not met: FAIL')\n",
    "\n",
    "    # check if disk is at least 90% full\n",
    "    usage = float(re.sub(\"\\D\", \"\", installDfOutput['Use%']))\n",
    "    if usage >= WARNINGATDISKUSE:\n",
    "        print(colPrint('Caution! Disk is {}% full'.format(usage),'O'))\n",
    "        \n",
    "    return(installDfOutput,availSize,summary,usage,diskFlag)\n",
    "    \n",
    "# ## Data drive and backup drive space and mounting check\n",
    "def dataAndBackupDriveCheck(summary):\n",
    "    # data and backup mount check\n",
    "    # define bash command for data drive\n",
    "    cmd = \"\"\"sudo chroot \"/opt/alation/alation\" /bin/su - alation\n",
    "    df -BG /data1/\"\"\"\n",
    "    # run bash command and get response\n",
    "    dataResponse = bashCMD(cmd)\n",
    "    # get df readout\n",
    "    dataDfOutput = processDfOutput(dataResponse)\n",
    "\n",
    "    # define bash command for backup drive\n",
    "    cmd = \"\"\"sudo chroot \"/opt/alation/alation\" /bin/su - alation\n",
    "    df -BG /data2/\"\"\"\n",
    "    # run bash command and get response\n",
    "    backupResponse = bashCMD(cmd)\n",
    "    # get df readout\n",
    "    backupDfOutput = processDfOutput(backupResponse)\n",
    "\n",
    "    # ensure the mounting points are different for data and backup\n",
    "    if dataDfOutput['Mounted_on'] != backupDfOutput['Mounted_on']:\n",
    "        mountFlag = True\n",
    "        print('Data and backup on different mount: {}'.format(colPrint('OK!','G')))\n",
    "        summary.append('Data and backup on different mounts: OK')\n",
    "    else:\n",
    "        print('Data and backup on different mount: {}'.format(colPrint('FAIL!','R')))\n",
    "        summary.append('Data and backup NOT on different mounts: FAIL')\n",
    "        mountFlag = False\n",
    "\n",
    "    # ensure the storage devices are different for data and backup\n",
    "    if dataDfOutput['Filesystem'] != backupDfOutput['Filesystem']:\n",
    "        storageFlag = True\n",
    "        print('Data and backup on different device: {}'.format(colPrint('OK!','G')))\n",
    "        summary.append('Data and backup on different devices: OK')\n",
    "    else:\n",
    "        storageFlag = False\n",
    "        print('Data and backup on different device: {}'.format(colPrint('FAIL!','R')))\n",
    "        summary.append('Data and backup NOT on different devices: FAIL')\n",
    "\n",
    "    # compare backup disk size and data disk size\n",
    "    backupToDataRatio = float(re.sub(\"\\D\", \"\", backupDfOutput['1G-blocks']))/float(re.sub(\"\\D\", \"\", dataDfOutput['1G-blocks']))\n",
    "\n",
    "    # check if backup disk is at least MINBACKUPFACTOR the size of data disk\n",
    "    if backupToDataRatio >= MINBACKUPFACTOR:\n",
    "        print('Backup disk to data disk size ratio is at least {}: {}'.format(MINBACKUPFACTOR,colPrint('OK!','G')))\n",
    "        summary.append('Backup disk space check passed: OK')\n",
    "    else:\n",
    "        print('Backup disk to data disk size ratio is {} which is lower than reccommended {}: {}'.format(backupToDataRatio,MINBACKUPFACTOR,colPrint('WARNING','O')))\n",
    "        summary.append('Backup disk space check not passed: WARNING')\n",
    "    \n",
    "    return(summary,backupToDataRatio,backupDfOutput,storageFlag,mountFlag,dataDfOutput)\n",
    "\n",
    "# ## Backup checks\n",
    "def confirmBackups(summary):\n",
    "    # confirm backups\n",
    "    # read in backup files\n",
    "    cmd = \"\"\"sudo chroot \"/opt/alation/alation\" /bin/su - alation\n",
    "    ls -l --block-size=M /data2/backup/\"\"\"\n",
    "    # run bash command and get response\n",
    "    response = bashCMD(cmd)\n",
    "\n",
    "    backupFilesTemp = response.split('\\n')\n",
    "    backupFiles = []\n",
    "    fileDatMap = {}\n",
    "    for each in backupFilesTemp:\n",
    "        if \"alation_backup.tar.gz\" in each:\n",
    "            # get date\n",
    "            dtTemp = each.split(' ')[-1]\n",
    "            # get filename\n",
    "            backupFiles.append(dtTemp)\n",
    "            # map filename to data\n",
    "            fileDatMap[dtTemp.split('_')[0][:8]] = each\n",
    "        \n",
    "\n",
    "    # extract the date information\n",
    "    backupDates = []\n",
    "    backupDTs = []\n",
    "    for each in backupFiles:\n",
    "        temp = each.split('_')[0][:8]\n",
    "        backupDates.append(temp)\n",
    "        tempDt = datetime.datetime.strptime(temp,'%Y%m%d').date()\n",
    "        backupDTs.append(tempDt)\n",
    "\n",
    "    # compute age of backups\n",
    "    today = datetime.date.today()\n",
    "\n",
    "    tDiff = []\n",
    "    diffRes = {}\n",
    "    for each in backupDTs:\n",
    "        diff = int((today - each).days)\n",
    "        tDiff.append(diff)\n",
    "        diffRes[diff] = each\n",
    "\n",
    "    # get the newest backup file\n",
    "    newestBackup = diffRes[min(tDiff)].strftime('%Y%m%d')\n",
    "    # get backup filesize information\n",
    "    response = fileDatMap[newestBackup]\n",
    "    # process the response (fize size in MB)\n",
    "    fileSize = float(response.split(' ')[4].replace('M',''))\n",
    "\n",
    "    # check if the backup filesize is at least 10 MB\n",
    "    if fileSize <= 10:\n",
    "        print(colPrint('Backup file size {} less than 10 MB'.format(fileSize),'R'))\n",
    "\n",
    "    # get the newest backup\n",
    "    newestBackup = diffRes[min(tDiff)].strftime('%Y-%m-%d')\n",
    "    # check age of the backup\n",
    "    if len(backupDates) >= 1:\n",
    "        if min(tDiff) <= MAXBACKUPAGE:\n",
    "            print('Recent backup available (Last backup on: {}, filesize: {}MB): {}'.format(newestBackup,fileSize,colPrint('OK!','G')))\n",
    "            summary.append('Backup check passed: OK')\n",
    "            backupFlag = True\n",
    "        else:\n",
    "            print('No recent backup available. (Last backup on: {}, age: {}): {}'.format(newestBackup,str(min(tDiff)),colPrint('FAIL!','R')))\n",
    "            backupFlag = False\n",
    "            summary.append('Backup check NOT passed: FAIL')\n",
    "    else:\n",
    "        print(colPrint('WARNING! No backup found!','R'))\n",
    "        summary.append('No backups found: FAIL')\n",
    "        backupFlag = False\n",
    "        \n",
    "    return(summary,backupFlag,backupFiles)\n",
    "\n",
    "# ## CPU and memory info\n",
    "def cpuMemData(summary):\n",
    "    # extract CPU information\n",
    "    # define commands\n",
    "    cmd = \"lscpu\"\n",
    "    # get response\n",
    "    cpuResponse = bashCMD(cmd)\n",
    "    # process response\n",
    "    lscpuOutput = lscpuParser(cpuResponse)\n",
    "\n",
    "    # get total memory information\n",
    "    # define commands\n",
    "    cmd = \"grep MemTotal /proc/meminfo\"\n",
    "    # get response\n",
    "    memResponse = bashCMD(cmd)\n",
    "    # process response\n",
    "    memResponse = lscpuParser(memResponse)\n",
    "    \n",
    "    return(summary,memResponse,lscpuOutput)\n",
    "\n",
    "# ## Mongo Check\n",
    "def mongoCheck(summary,fullLog):\n",
    "    # mongoDB check\n",
    "    cmd = \"\"\"sudo chroot \"/opt/alation/alation\" /bin/su - alation\n",
    "    du -k --max-depth=0 -BG /data1/mongo/\"\"\"\n",
    "    # get response\n",
    "    response = bashCMD(cmd)\n",
    "\n",
    "    # parase the response\n",
    "    mongoSize = float(re.sub(\"\\D\", \"\", response.split('\\t')[0]))\n",
    "    fullLog['mongoSize'] = response.split('\\t')[0]\n",
    "\n",
    "    # check if available disk space is at least MONGOx the size of mongoDB\n",
    "    availDataSpace = float(re.sub(\"\\D\", \"\", fullLog['dataDirDf']['Available']))\n",
    "\n",
    "    if availDataSpace/mongoSize > MONGOx:\n",
    "        print('Available space {}GB is at least {}x greater than mongoDB size {}GB: {}'.format(availDataSpace,MONGOx,mongoSize,colPrint('OK!','G')))\n",
    "        summary.append('MongoDB space check passed: OK')\n",
    "        mongoFlag = True\n",
    "    else:\n",
    "        print('{} Not enough space available space to update to Alation V R2 or high! Mongo size = {}, available size = {}.'.format(colPrint('FAIL!','R'),mongoSize,availDataSpace))\n",
    "        mongoFlag = False\n",
    "        summary.append('MongoDB space check not passed: FAIL')\n",
    "    \n",
    "    return(summary,mongoFlag,fullLog,availDataSpace,mongoSize)\n",
    "    \n",
    "# ## postgreSQL Check\n",
    "def pgSQLCheck(summary,fullLog):\n",
    "    # postgreSQL check\n",
    "    cmd = \"\"\"sudo chroot \"/opt/alation/alation\" /bin/su - alation\n",
    "    du -k --max-depth=0 -BG /data1/pgsql/\"\"\"\n",
    "    # get response\n",
    "    response = bashCMD(cmd)\n",
    "\n",
    "    # parase the response\n",
    "    pgsqlSize = float(re.sub(\"\\D\", \"\", response.split('\\t')[0]))\n",
    "    fullLog['pgsqlSize'] = response.split('\\t')[0]\n",
    "\n",
    "    # run the check\n",
    "    if availDataSpace/pgsqlSize > PGSQLx:\n",
    "        print('(For Alation Analytics) Available space {}GB is at least {}x greater than postgreSQL size {}GB: {}'.format(availDataSpace,PGSQLx,pgsqlSize,colPrint('OK!','G')))\n",
    "        summary.append('postgreSQL for Analytics space check passed: OK')\n",
    "        pgsqlFlag = True\n",
    "    else:\n",
    "        print('{} Not enough space available space to turn on analytics. postgreSQL size = {}, available size = {}.'.format(colPrint('WARNING','O'),pgsqlSize,availDataSpace))\n",
    "        pgsqlFlag = False\n",
    "        summary.append('postgreSQL for Analytics space check not passed: FAIL')\n",
    "\n",
    "    # ## combined space check\n",
    "    fullSpaceNeeded = pgsqlSize*PGSQLx + mongoSize*MONGOx\n",
    "\n",
    "    # check against available space\n",
    "    if availDataSpace > fullSpaceNeeded:\n",
    "        print('Available space, {}GB, is greater than the combined space needed, {}GB: {}'.format(availDataSpace,fullSpaceNeeded,colPrint('OK!','G')))\n",
    "        combinedSpaceFlag = True\n",
    "    else:\n",
    "        spaceDiff = abs(fullSpaceNeeded - availDataSpace)\n",
    "        print('{} Combined space check Please expand /opt/alation/ drive by {}GB before turning on analytics!'.format(colPrint('WARNING!','O'),spaceDiff))\n",
    "        combinedSpaceFlag = False\n",
    "        \n",
    "    return(combinedSpaceFlag,pgsqlFlag,summary,fullLog)\n",
    "\n",
    "# ## datadog check\n",
    "def dataDogCheck(fullLog):\n",
    "    # Datadog check\n",
    "    key,val = alationConfQuery('datadog.enabled')\n",
    "    fullLog[key] = val\n",
    "\n",
    "    if val == 'False':\n",
    "        print(\"{} Datadog not enabled!\".format(colPrint('WARNING','O')))\n",
    "        datadogFlag = False\n",
    "    elif val == 'True':\n",
    "        print(\"Datadog enabled: \".format(colPrint('OK!','G')))\n",
    "        datadogFlag = True\n",
    "        \n",
    "    return(fullLog,datadogFlag)\n",
    "    \n",
    "## # Extract site ID\n",
    "def siteIDExtract(fullLog):\n",
    "    # site_id\n",
    "    key,siteID = alationConfQuery('site_id')\n",
    "    fullLog[key] = siteID\n",
    "    \n",
    "    return(fullLog,siteID)\n",
    "    \n",
    "# ## Schema Equivalance Check\n",
    "def seCheck():\n",
    "    # try to run the code which should have been created earlier\n",
    "    try:\n",
    "        # create bash command\n",
    "        cmd = \"\"\"sudo chroot \"/opt/alation/alation\" /bin/su - alation\n",
    "        python /opt/alation/django/rosemeta/one_off_scripts/schemaEquivalance.py\"\"\"\n",
    "\n",
    "        # get response\n",
    "        seResponse = bashCMD(cmd)\n",
    "\n",
    "        # obtain the check result\n",
    "        res = int(seResponse.split(',')[0].split(':')[1])\n",
    "\n",
    "        # pass case\n",
    "        if res == 0:\n",
    "            # print the success message\n",
    "            print(\"Schema Equivalance Check: {}\".format(colPrint('OK!','G')))\n",
    "            seFlag = True\n",
    "        else:\n",
    "            # failure case\n",
    "            print('Schema Equivalance Check: {}'.format(colPrint('FAIL!','R')))\n",
    "            print('Check Result: {}'.format(res))\n",
    "            seFlag = False\n",
    "\n",
    "    # if not, then try running curl\n",
    "    except:\n",
    "        print(colPrint('Cannot find schema equivalance check code created earlier. Tryin to curl code form GitHub.','O'))\n",
    "        # ## Schema Equivalance Check\n",
    "        # create bash command\n",
    "        cmd = \"\"\"sudo chroot \"/opt/alation/alation\" /bin/su - alation\n",
    "        cd /opt/alation/django/rosemeta/one_off_scripts/\n",
    "        sudo curl https://raw.githubusercontent.com/mandeepsingh-alation/schemaEquivalence/master/schemaEquivalance.py --output schemaEquivalance.py\n",
    "        python schemaEquivalance.py\"\"\"\n",
    "\n",
    "        # get response\n",
    "        seResponse = bashCMD(cmd)\n",
    "\n",
    "        # obtain the check result\n",
    "        res = int(seResponse.split(',')[0].split(':')[1])\n",
    "\n",
    "        # pass case\n",
    "        if res == 0:\n",
    "            # print the success message\n",
    "            print(\"Schema Equivalance Check: {}\".format(colPrint('OK!','G')))\n",
    "            seFlag = True\n",
    "        else:\n",
    "            # failure case\n",
    "            print('Schema Equivalance Check: {}'.format(colPrint('FAIL!','R')))\n",
    "            print('Check Result: {}'.format(res))\n",
    "            seFlag = False\n",
    "            \n",
    "    return(seFlag)\n",
    "\n",
    "\n",
    "# ## Configuration parameters\n",
    "# config\n",
    "# minimum empty disk requirement\n",
    "MINDISKSPACE = 8.0\n",
    "# warn if disk is at or above below percentage\n",
    "WARNINGATDISKUSE = 90.0\n",
    "# critical MINIMUM major version to check for\n",
    "CRITICALVERSION = 4\n",
    "# maximum acceptable age of a backup in days\n",
    "MAXBACKUPAGE = 5\n",
    "# the minimum size of backup disk as a multiple of data disk\n",
    "# e.g. 1.5 checks size(backup disk)/size(data disk) >= 1.5\n",
    "MINBACKUPFACTOR = 1.5\n",
    "# mongoDB size requirements\n",
    "MONGOx = 2\n",
    "# postgreSQL multiplication factor for analytics\n",
    "# in order to turn on analytics, the pgsql folder will doulbe \n",
    "# in size.\n",
    "PGSQLx = 2\n",
    "\n",
    "# summary object for the end\n",
    "summary = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version information check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    versionData,majorVersion,minorVersion,patchVersion,buildVersion,version,versionFlag,flag410,summary = versionCheck(summary)\n",
    "except:\n",
    "    versionFlag = False\n",
    "    flag410 = False\n",
    "    \n",
    "    print(colPrint('WARNING! Version check failed! Please make sure Alation version is > 4.10.x','R'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replication mode check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    summary,replicationMode,replicationFlag = replicationCheck(summary)\n",
    "except:\n",
    "    replicationFlag = False\n",
    "    print(colPrint('WARNING! Replication check failed! Please make sure the installation is standalone!','R'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimum space requirement check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    installDfOutput,availSize,summary,usage,diskFlag = minSpaceCheck(summary)\n",
    "except:\n",
    "    diskFlag = False\n",
    "    print(colPrint('WARNING! Minimum space check failed! Please make sure /opt/alation has 8GB free space.','R'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data drive and backup drive space and mounting check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    summary,backupToDataRatio,backupDfOutput,storageFlag,mountFlag,dataDfOutput = dataAndBackupDriveCheck(summary)\n",
    "except:\n",
    "    storageFlag,mountFlag = False,False\n",
    "    print(colPrint('WARNING! Could not verify separation of data and backup disk!','R'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backup checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    summary,backupFlag,backupFiles = confirmBackups(summary)\n",
    "except:\n",
    "    print(colPrint('WARNING! Could not verify backups!','R'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CPU and memory info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    summary,memResponse,lscpuOutput = cpuMemData(summary)\n",
    "except:\n",
    "    print(colPrint('Could not obtain CPU and memory Information','O'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # parse out version data collected before\n",
    "    vDataTemp = list(map(lambda x: versionParser(x),versionData))\n",
    "    keys = list(map(lambda x: x[0],vDataTemp))\n",
    "    values = list(map(lambda x: x[1],vDataTemp))\n",
    "    fullLog = dict(zip(keys,values))\n",
    "\n",
    "    # add previously obtained data\n",
    "    fullLog['backupFiles'] = backupFiles\n",
    "    fullLog['Replication'] = replicationMode\n",
    "    fullLog['installDirDf'] = installDfOutput\n",
    "    fullLog['dataDirDf'] = dataDfOutput\n",
    "    fullLog['backupDirDf'] = backupDfOutput\n",
    "    fullLog['backupToDataRatio'] = backupToDataRatio\n",
    "    fullLog['cpuData'] = lscpuOutput\n",
    "    fullLog['totalMemory'] = memResponse.values()[0]\n",
    "except:\n",
    "    fullLog={}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mongo Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    summary,mongoFlag,fullLog,availDataSpace,mongoSize = mongoCheck(summary,fullLog)\n",
    "except:\n",
    "    mongoFlag = False\n",
    "    print(colPrint('WARNING! Could not check disk space for MongoDB!','R'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## postgreSQL Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    combinedSpaceFlag,pgsqlFlag,summary,fullLog = pgSQLCheck(summary,fullLog)\n",
    "except:\n",
    "    combinedSpaceFlag,pgsqlFlag = False,False\n",
    "    print(colPrint('Caution! Could not verify the space requirements for Alation Analytics!','O'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query alation_conf for Datadog check, client_id, and site_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    fullLog,datadogFlag = dataDogCheck(fullLog)\n",
    "except:\n",
    "    datadogFlag = False\n",
    "    print(colPrint('Datadog status could not be verified!','O'))\n",
    "    \n",
    "## # Extract site ID\n",
    "try:\n",
    "    fullLog,siteID = siteIDExtract(fullLog)\n",
    "except:\n",
    "    siteID = 'NA'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schema Equivalance Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    seFlag = seCheck()\n",
    "except:\n",
    "    print(colPrint('WARNING! Could not perform schema equivalance check','R'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finish up the check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add current time\n",
    "ts = time.time()\n",
    "fullLog['creationTime'] = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# write data to disk\n",
    "# data filename\n",
    "dfName = \"/tmp/dataOutput_{}.json\".format(siteID)\n",
    "# write to disk\n",
    "with open(dfName, \"w\") as f:\n",
    "    json.dump(fullLog,f)\n",
    "\n",
    "# process the summary\n",
    "summaryStr = '\\n'.join(summary)\n",
    "# summary filename\n",
    "sfName = \"/tmp/summary_{}.txt\".format(siteID)\n",
    "# write to disk\n",
    "with open(sfName,'w') as f:\n",
    "    f.writelines(summaryStr)\n",
    "    \n",
    "\n",
    "# print our the full log\n",
    "print('##########')\n",
    "print(fullLog)\n",
    "print('##########')\n",
    "\n",
    "# create, share, and save a summary\n",
    "# everything worked\n",
    "if versionFlag and not flag410 and backupFlag and storageFlag and mountFlag and diskFlag and replicationFlag and seFlag:\n",
    "    print(colPrint('All critical checks passed.\\nPlease copy and send all the output back to Alation!','G'))\n",
    "    print('Upgrade Readiness Check complete.')\n",
    "# now enough storage\n",
    "elif not diskFlag:\n",
    "    print(colPrint('Not enough empty space on /opt/alation!','R'))\n",
    "# backup processing failed\n",
    "elif not backupFlag:\n",
    "    print(colPrint('Do not proceed with upgrade. Please check backup!','R'))\n",
    "# not enough mongo space\n",
    "elif not mongoFlag:\n",
    "    print(colPrint('Not enough space for mongoDB!','R'))\n",
    "elif not replicationFlag:\n",
    "    print(colPrint('Please follow the High-Availability install instructions here: https://alationhelp.zendesk.com/hc/en-us/articles/360011041633-Release-Specific-Update-Pre-Checks','O'))\n",
    "elif flag410:\n",
    "    print(colPrint('Alation version is lower than 4.10.x. Please see https://alationhelp.zendesk.com/hc/en-us/articles/360011041633-Release-Specific-Update-Pre-Checks','O'))\n",
    "elif not mountFlag or not storageFlag:\n",
    "    print(colPrint('Backup and data drives share same device!','O'))\n",
    "elif not versionFlag:\n",
    "    print(colPrint('Please contact customer care. Version not supported!','R'))\n",
    "elif not seFlag:\n",
    "    print(colPrint('Please contact customer care. Schema equivalence check failed!','R'))\n",
    "    print(seResponse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
